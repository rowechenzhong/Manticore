Readout for Mahabharata BPE with pretokenization, size 4000 cap 10, (low merge cutoff 1000).

```
Corpus length: 16184097
Pre-tokenizing: 16181000 of 16184097 frequency size is 88593
Completed trie insertion
Completed tokenization
Saved tokens to file: ..//tokenizer_outputs//mahabharata_size4000_cap10.txt
Beginning tokenize
Finished tokenizing
Saving tokenization
Compression ratio:0.458535
Token length 0: 0
Token length 1: 256
Token length 2: 474
Token length 3: 1194
Token length 4: 929
Token length 5: 515
Token length 6: 280
Token length 7: 160
Token length 8: 94
Token length 9: 60
Token length 10: 38
```

Unlimited Token Length (a tiny bit worse??)

```
Corpus length: 16184097
Pre-tokenizing: 16181000 of 16184097 frequency size is 88593
Completed trie insertion
Completed tokenization
Saved tokens to file: ..//tokenizer_outputs//mahabharata_size4000_cap10000.txt
Beginning tokenize
Finished tokenizing
Saving tokenization
Compression ratio:0.459705
Token length 0: 0
Token length 1: 256
Token length 2: 467
Token length 3: 1155
Token length 4: 875
Token length 5: 476
Token length 6: 259
Token length 7: 148
Token length 8: 88
Token length 9: 56
Token length 10: 36
Token length 11: 27
Token length 12: 21
Token length 13: 17
Token length 14: 15
Token length 15: 14
Token length 16: 13
Token length 17: 12
Token length 18: 11
Token length 19: 10
Token length 20: 9
Token length 21: 8
Token length 22: 7
Token length 23: 6
Token length 24: 5
Token length 25: 4
Token length 26: 3
Token length 27: 2
```

Max token length = 5 (much worse)

```
Corpus length: 16184097
Pre-tokenizing: 16181000 of 16184097 frequency size is 88593
Completed trie insertion
Completed tokenization
Saved tokens to file: ..//tokenizer_outputs//mahabharata_size4000_cap5.txt
Beginning tokenize
Finished tokenizing
Saving tokenization
Compression ratio:0.464563
Token length 0: 0
Token length 1: 256
Token length 2: 517
Token length 3: 1362
Token length 4: 1175
Token length 5: 690
```
